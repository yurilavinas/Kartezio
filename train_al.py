# import pkg_resources
# pkg_resources.require("Kartezio==1.0.0a1")

from kartezio.dataset import read_dataset
from kartezio.plot import save_prediction
from kartezio.activeLearning import active_learning
from kartezio.utils.viewer import KartezioViewer

import sys
import os
import numpy as np
import yaml

if __name__ == '__main__':

    if len(sys.argv) < 2:
        print("Usage\n: python train_model_ative_learning_interactive.py (config, yml file) config.yml (run, int) run")
        sys.exit()
    else:       
        with open(sys.argv[1], "r") as ymlfile:
            cfg = yaml.safe_load(ymlfile)

    AL = active_learning(cfg)

    try:
        os.makedirs(AL.save_results)
    except:
        print('folder already exists, continuing...')

    
    AL.run = int(sys.argv[2])
    
    AL.create_file()
    
    for cycle in range(AL.iter):
        print("cycle #",cycle,"of AL. Running",AL.n_models,"cgp models.") 
        if AL.verbose:
            print("using data from", AL.lvls)

        # loading data for training
        if AL.name == "cellpose":
            dataset = read_dataset(AL.DATASET, indices=AL.lvls, preview=False)
        elif AL.name == "ssi":
            dataset = read_dataset(AL.DATASET, indices=AL.lvls, filename=AL.filename, meta_filename=AL.meta_filename, preview=False)
            
        # create the output folder for each model - saving elite and population history
        if cycle == 0:
            AL.init_model()
        
        train_x, train_y = dataset.train_xy
        if AL.name == "cellpose":
            train_x = AL.preprocessing.call(train_x)
        
        # train with the images available so far - small imgs 
        # either the img is from an annotated area
        # or it's randomly selected - right now i picked the most interesting imgs            
        for i, model in enumerate(AL.models):
            # file = save_results + "_/internal_model_"+str(i)+"_data.txt"
            AL.strategies[i], AL.elites[i] = model.fit(train_x, train_y, elite = AL.elites[i])

        if AL.method == "disagreement":
            AL.disagreement = AL.calc_disagreement(AL.indices) 
        # get the elite from each model
        for i, model in enumerate(AL.models):
            y_hats, _ = model.predict(train_x)
            AL.fitness[i] = AL.strategies[i].fitness.compute_one(train_y, y_hats)

        ### saving test data and performance ###
        AL.saving_test(cycle)
        
        # active learning
        # rm img if more than 1 img is in use
        if len(AL.lvls) > 1:
            if AL.img_t > .0:
                AL.rm_img()

        # active learning
        # add img if there are imgs to add
        if len(AL.indices) > 0:  # if there are still imgs to add 
            AL.add_img()
            
        else:
            AL.ask_user = True
            if AL.verbose:
                print("no more data to add...")
        
        if AL.ask_user: # if there's no data to add, ask the user for more data/evaluation of the model   
            if AL.verbose:
                print("asking the user for support...")
            
            # get the mask that the user thought it's the best
            # interactive part
            AL.user_input()

            # restart the training ?
            # AL.lvls.append(AL.idx)
        AL.ask_user = False
        
        # update status of the running models
        AL.update_stats()
            
        AL.status = ['continue']*AL.n_models


    if AL.name == "cellpose":
        dataset_ssi = read_dataset(AL.DATASET, indices=None)
    elif AL.name == "ssi":
        dataset = read_dataset(AL.DATASET, indices=AL.lvls, filename=AL.filename, meta_filename=AL.meta_filename, preview=False)
        
    test_x, test_y, test_v = dataset.test_xyv
    test_x = AL.preprocessing.call(test_x) 

    # saving the masks generated by the elites
    # so that we can look and evaluate
    for i, model in enumerate(AL.models):  
        model.save_elite(f"{AL.save_results}/elite_{i}_run_{AL.run}.json", dataset_ssi)  
        y_hat, _ = model.predict(test_x)
        imgs_name = f"{AL.save_results}/gen_{cycle}_model_{i}_run_{AL.run}_mask.png"
        save_prediction(imgs_name, test_v[0], y_hat[0]["mask"])
        # imgs_name = f"{save_results}/gen_{cycle}_model_{i}_run_{AL.run}_markers.png"
        # save_prediction(imgs_name, test_v[0], y_hat[0]["markers"])
        # imgs_name = f"{save_results}/gen_{cycle}_model_{i}_run_{AL.run}_labels.png"
        # save_prediction(imgs_name, test_v[0], np.astype(y_hat[0]["labels"],np.uint8))

        viewer = KartezioViewer(
            model.parser.shape, model.parser.function_bundle, model.parser.endpoint
        )
        model_graph = viewer.get_graph(
            AL.elites[i], inputs=["In_1","In_2","In_3"], outputs=["out_1", "out_2"]
        )
        path = f"{AL.save_results}/graph{cycle}_model_{i}_run_{AL.run}_.png"
        model_graph.draw(path=path)


